---
title: "analyze"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(tidyverse)
library(lubridate)
library(memoise)
```


```{r utilities}
generic.ci_ <- function(x, n = 5000, seed = 1) {
  set.seed(seed)
  lenx = length(x)
  
  structure(
    quantile(
      replicate(n, mean(x[sample.int(lenx, replace = TRUE)])),
      c(0.025, 0.975)),
    names=c("ci.l","ci.u"))
}

generic.ci <- memoise(generic.ci_)
```

# read in data

```{r}
results.dir = "production-results/"
assignments = read_csv(paste0(results.dir, "assignments.csv")) %>%
  mutate(accept.time = ymd_hms(accept.time),
         submit.time = ymd_hms(submit.time),
         duration = difftime(submit.time, accept.time, units = "mins"))
responses = read_csv(paste0(results.dir, "responses.csv"),
                     col_types = cols(string = col_character()))
```


```{r compute-example-correctness}
regexes = c('3a' = 'aaa+',
            'zip-code' = '[0123456789]{5}',
            'consonants-only' = '[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]*',
            'delimiters' = "\\[.*\\]")

example.matches = function(example, rx) {
  res = regexpr(pattern = rx, text = example)
  # make sure we match and that the *entire* string is what matches, not a substring
  res > 0 & attr(res, "match.length") == nchar(example)
}
# example.correct(example = 'aaa', rx = 'aaa+')
# example.correct(example = 'baaa', rx = 'aaa+')
# example.correct(example = 'aaaa', rx = 'aaa+')

responses = responses %>%
  mutate(rx = regexes[rule.id])

responses_match = apply(responses[,c('string','rx')],
      1,
      function(e) { example.matches(example = e['string'], rx = e['rx']) })

responses = mutate(responses,
                   match = responses_match,
                   correct = !xor(polarity == 'positive', match)) %>%
  select(-rx, -rule.desc) # hide these cause they're verbose

# # testing
# View(responses %>% select(rule.id, polarity, string, correct, match) %>% arrange(rule.id, polarity))
```


# user experience

## how long does the task take?

```{r}
qplot(data = assignments,
      x = as.numeric(duration),
      binwidth = 1,
      color = I('white')) + 
  xlab("duration (minutes)")
```


## what did people think was a fair payment?

```{r}
fair.pay = assignments$fair_pay %>% as.numeric %>% na.omit
fair.pay = fair.pay[fair.pay < 5]
qplot(x = fair.pay,
      binwidth = 0.1,
      color = I('white')
      )
```

# research

## how many examples do people give?

```{r, fig.width = 11, fig.height = 3}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.examples = n()) %>%
  group_by(worker.id, rule.id, num.examples) %>%
  summarise(freq = n())

xmin = 1 #min(e.agg$num.examples)
xmax = max(e.agg$num.examples)

e.agg$num.examples.fct = factor(e.agg$num.examples, levels = as.character(xmin:xmax))

ggplot(data = e.agg) +
  facet_grid(. ~ rule.id) +
  geom_bar(mapping = aes(x = num.examples.fct, y = freq), stat = 'identity') +
  scale_x_discrete(breaks = as.character(xmin:xmax), drop = FALSE, name = 'number of examples')
```

exactly 2 seems to be common

## q: do 2-examples tend to be *balanced*? i.e., one positive and one negative?

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2) %>%
  group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == 'positive'),
            num.neg = sum(polarity == 'negative'))

print(table(e.agg$num.pos, e.agg$num.neg))

# proportion test on the frequency of balanced 2-examples
prop.test(x = sum(e.agg$num.pos == 1), nrow(e.agg))
```

overwhelmingly, yes (nb: would need to collect more data for the proportion test, which i believe operates better if the minimum cell count is 5)

### for balanced 2-examples, what is the mean edit distance?

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2, sum(polarity == 'positive') == 1) %>%
  summarise(edit.distance = adist(string)[1,2])

qplot(data = e.agg,
      x = edit.distance,
      color = I('white'),
      binwidth = 1) + scale_x_continuous(breaks = with(e.agg, min(edit.distance):max(edit.distance)))
```

TODO: figure out if these examples are closer than you'd expect by chance (permutation test)

#### the second most likely edit distance for balanced 2-examples is 5: is there a pattern there? or is that just the zip code rule?

```{r}
responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2, sum(polarity == 'positive') == 1) %>%
  summarise(edit.distance = adist(string)[1,2]) %>%
  filter(edit.distance == 5) %>%
  select(-edit.distance) %>%
  merge(responses)
```

yes, mostly

## how many positive examples versus negative examples?

```{r, fig.width = 11, fig.height = 3}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == "positive"),
            num.neg = sum(polarity == "negative"))

qplot(data = e.agg,
      facets = . ~ rule.id,
      x = num.pos,
      y = num.neg, alpha = I(0.6)) +
  geom_abline() + 
  scale_x_continuous(name = '# positive examples', breaks = c(0, 3, 6), limits = c(0, 6)) +
  scale_y_continuous(name = '# negative examples', breaks = c(0, 3, 6), limits = c(0, 6))
```

## how related are the examples in edit distance?

```{r}
cluster.examples = function(strings, distance.threshold = 2) {
  distance.matrix = adist(strings)
  
  # for each string, figure out which other strings it's similar to
  # (i.e., has edit distance less than the threshold)
  similarities = apply(distance.matrix,
        1,# by row
        function(row) {
          which(row <= distance.threshold)
        })
  clusters = list()
  # print(similarities)
  
  # make the clusters
  Map(1:length(strings),
      f = function(i) {
        # j is the index of the previously created cluster that can contain this string
        j = Position(x = clusters,
                     f = function(cluster) { i %in% cluster })
        
        if (is.na(j)) {
          clusters[[length(clusters) + 1]] <<- similarities[[i]]
        } else {
          clusters[[j]] <<- union(clusters[[j]], similarities[[i]])
        }
      })
  
  Map(clusters,
      f = function(indices) { strings[indices] })
}

# # testing
# strings = c("01234", "012a4", "62804", "628041", "y6280", "0123", "280", "a280b")
# #strings = c('aaa','aa','aaab','baaaab','bbaaabb')
# ## strings = c("94301", "40510", "33333", "r2349", "asdfa", "3621", "834920")
# cluster.examples(strings)
```

```{r}
responses.clustered = responses %>%
  group_by(worker.id, rule.id) %>%
  summarise(num.examples = n(),
            num.clusters = length(cluster.examples(string)))

responses.clustered %>% group_by(worker.id) %>% summarise(mean_num.clusters = mean(num.clusters))

mean.num.clusters = mean(responses.clustered$num.clusters)
mean.num.clusters
```


TODO: do there tend to be more negative examples within a cluster? (i think people might come up with one example and then demonstrate various ways it can be perturbed to be a non-example)

comparison to permutation test: sample random participants by sampling from pool of all participants' responses (note that this is sampling *without* replacement, as people wouldn't give the same example twice)

```{r}
sample.bootstrap.subject = function(worker.id, rule.id) {
  # get examples given by all participants for this rule
  ## written in non-dplyr syntax because i think it might be faster?
  pool = responses[responses$rule.id == rule.id,]
  pool.pos = pool[pool$polarity == 'positive',]$string
  pool.neg = pool[pool$polarity == 'negative',]$string
  
  # get this worker's examples
  this = pool[pool$worker.id == worker.id,]
  
  num.pos = sum(this$polarity == 'positive')
  num.neg = sum(this$polarity == 'negative')
  
  syn.pos = sample(x = pool.pos, size = num.pos, replace = FALSE)
  syn.neg = sample(x = pool.neg, size = num.neg, replace = FALSE)
  
  c(num.clusters = length(cluster.examples(c(syn.pos, syn.neg))))
}

workers.and.rules = responses.clustered[,c('worker.id', 'rule.id')]

clusters.bootstrap = function() {
  num.clusters = apply(workers.and.rules,
                       1,
                       function(e) { 
                         sample.bootstrap.subject(e['worker.id'], e['rule.id'])
                       })
  
  mean(num.clusters)
}

# a little slow because my clustering function is not vectorized
time = system.time(bootstrap.samples <- replicate(5000, clusters.bootstrap()))

writeLines(paste0("elapsed seconds: ", round(unname(time['elapsed']), 1)))

writeLines(paste0('95% ci for bootstrap: ', paste0(quantile(bootstrap.samples, c(0.025, 0.0975)), collapse = " - ")))

# one-tailed test: how many bootstrap samples have a mean
# number of clusters less than the observed sample?
sum(bootstrap.samples < mean.num.clusters) / length(bootstrap.samples)
```

## how many mistakes do people make? (e.g., positive examples that don't actually match or negative examples that do match)


by stimulus:

```{r}
responses %>%
  group_by(rule.id) %>%
  summarise(error.rate = sum(!correct) / n())
```

inspecting errors:

```{r}
responses %>% filter(!correct) %>% select(rule.id, worker.id, string, polarity, match, correct) %>% arrange(rule.id)
```

issues
- 3a: ambiguity about lower versus upper case. also, it needs to be clearer that the string contains *only* a's.
- zip-code: the zip code framing might be too semantic. people might be thinking "give examples of *real* zip codes"



by person:
```{r}
responses %>%
  group_by(worker.id) %>%
  summarise(error.rate = sum(!correct) / n()) %>% 
  arrange(desc(error.rate))
```

## how long are the examples that people give?

by stimulus:

```{r, fig.width = 11, fig.height = 3}
qplot(data = responses,
      facets = . ~ rule.id,
      x = nchar(string),
      binwidth = 1,
      color = I('white'))
```

by person:

```{r}
qplot(data = responses,
      x = worker.id,
      y = nchar(string), alpha = I(0.5)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## do people give examples in particular orders? e.g., shorter ones first or positive ones first?

### length

un-zscored:
```{r}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(example.num) %>%
  summarise(mean.len = mean(len),
            cl.len = generic.ci(len)['ci.l'],
            cu.len = generic.ci(len)['ci.u']) %>%
  ungroup

qplot(data = e,
      x = example.num,
      y = mean.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```

note: confidence intervals for last two points are actually huge (very few unique data values, e.g., 1)

z-scoring length per subject per rule:
```{r}
z.score <- function(xs) {
  centered = xs - mean(xs)
  if (length(xs) == 1) {
    centered
  } else {
    # NB: deliberately doesn't catch the case where all xs are the same
    # because i filter for this later on
    centered / sd(xs)
  }
}

e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len)) %>%
  filter(!is.nan(z.len)) %>%
  group_by(example.num) %>%
  summarise(mean.z.len = mean(z.len),
            cl.len = generic.ci(z.len)['ci.l'],
            cu.len = generic.ci(z.len)['ci.u']) %>%
  ungroup

qplot(data = e,
      x = example.num,
      y = mean.z.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```

doesn't appear to be any sequencing over all the participants, though there are certainly cases where this happens:

```{r}
responses %>% filter(worker.id == '26e3c2f', rule.id == '3a')
```

i wonder if such simple->complex sequencing is better for receivers (ERRATUM-minor: i called this d02 task receiving but it's actually sending). i could test this by presenting receivers with different permutations of a given sequence.


### polarity

```{r}
e = responses %>%
        group_by(example.num) %>%
        summarise(frac.pos = sum(polarity == 'positive') / n(),
                  ci.l = generic.ci(polarity == 'positive')['ci.l'],
                  ci.u = generic.ci(polarity == 'positive')['ci.u'])

qplot(data = e,
      x = example.num,
      y = frac.pos,
      ymin = ci.l,
      ymax = ci.u,
      geom = c('pointrange','line'))
```

interesting -- first example tends to be positive

# TODO

- do positive examples tend to be followed by negative examples?
- do positive examples tend to be dissimilar from other positive examples? (but similar to a subset of negative examples) [metaphor -- a positive example as a primary tentpole that supports a number of negative example tentpoles]#### within a cluster, does the first example tend to be positive?

TODO

# misc

did 90210 show up as a zip code much?
```{r}
responses %>% filter(rule.id == 'zip-code', string == '90210')
```

no -- only once. i wonder if people were more likely to use their own zip code (could try reconciling with geolocation)


# looking at raw examples

## 3a

## consonants-only

4 people gave "aeiou":
```{r}
filter(responses, rule.id == 'consonants-only') %>% filter(string == 'aeiou') %>% nrow
```


i think this is a good example sequence:

```{r}
filter(responses, worker.id == '1ec52d4', rule.id == 'consonants-only') %>% select(example.num, polarity, string)
```

i think this is a bad example sequence, as it doesn't make clear the difference between positive and negative examples (also, there is an error -- #6 is a negative example but it actually doesn't contain any consonants. DOH -- there are other alternatives to the consonants-only rule besides vowels. you can include numbers too.)

```{r}
filter(responses, worker.id == '26e3c2f', rule.id == 'consonants-only') %>% select(example.num, polarity, string)
```

(initially i was a little worried that this person was just mashing random keys but they didn't do that for the other rules, so it seems unlikely)

an interesting sequence i'm curious how good these examples are:
```{r}
filter(responses, worker.id == '4ba0325', rule.id == 'consonants-only') %>% select(example.num, polarity, string)
```


## delimiters

### no one nested the brackets (either positively or negatively)

```{r}
responses %>% filter(rule.id == 'delimiters')
```


## zip-code

### negative examples tend to be purely numeric (though there are a few exceptions)

```{r}
e = responses %>%
  filter(rule.id == 'zip-code', polarity == 'negative') %>%
  {example.matches(.$string, "[0123456789]+")}

print(table(e))

prop.test(x = sum(e == TRUE), n = length(e))
```


